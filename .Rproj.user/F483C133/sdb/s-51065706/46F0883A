{
    "collab_server" : "",
    "contents" : "#Identify projects which can be compared to LD based on triangulation.\n\ngen.gef.mfa <- function(gef.source, gef.mfa.eval.CD, gef.mfa.eval.MFA,\n                        gef.aiddata.locations, gef.aiddata.projects,\n                        gef.aiddata.ancillary)\n{\n  \n  gef.source.dta <- read.csv(gef.source)\n  gef.mfa.eval.CD.dta <- read.csv(gef.mfa.eval.CD)\n  gef.mfa.eval.MFA.dta <- read.csv(gef.mfa.eval.MFA)\n  \n  gef.aiddata.locations.dta <- read.csv(gef.aiddata.locations)\n  gef.aiddata.projects.dta <- read.csv(gef.aiddata.projects)\n  gef.aiddata.ancillary.dtaA <- read.csv(gef.aiddata.ancillary)\n  #Omit non-complete cases from the ancillary.\n  gef.aiddata.ancillary.dtaB <- gef.aiddata.ancillary.dtaA[complete.cases(gef.aiddata.ancillary.dtaA),]\n  \n  #Remove duplicates - won't be an issue in the final data, but lets keep this to be safe.\n  gef.aiddata.ancillary.dta <- gef.aiddata.ancillary.dtaB[duplicated(gef.aiddata.ancillary.dtaB$GEF_ID),]\n  \n  #Join everything to the locations table.\n  gef.fullA <- merge(gef.aiddata.locations.dta, gef.aiddata.projects.dta[c(\"AidData.Project.ID\", \"Donor.Project.ID\")], \n                    by.x=\"AidData.ID\", by.y=\"AidData.Project.ID\", all.x=TRUE, all.y=FALSE)\n  \n  gef.fullB <- merge(gef.fullA, gef.aiddata.ancillary.dta, \n                     by.x=\"Donor.Project.ID\", by.y=\"GEF_ID\", all.x=TRUE, all.y=FALSE) \n  \n  gef.fullC <- merge(gef.fullB, gef.source.dta, \n                     by.x=\"Donor.Project.ID\", by.y=\"GEF_ID\", all.x=TRUE)\n  \n  gef.fullD <- merge(gef.fullC, gef.mfa.eval.CD.dta, \n                     by.x=\"Donor.Project.ID\", by.y=\"GEF.ID\", all.x=TRUE)\n  \n  gef.fullE <- merge(gef.fullD, gef.mfa.eval.MFA.dta, \n                     by.x=\"Donor.Project.ID\", by.y=\"GEF.ID\", all.x=TRUE)\n  \n  gef.full <- gef.fullE\n  \n  return(gef.full)\n  \n}\n\nprep.ld <- function(ld, \n                    ld.ancil)\n{\n  ld.spdf <- geojson_read(ld, what=\"sp\")\n  ld.ancil.csv <- read.csv(ld.ancil)\n  \n  return(merge(ld.spdf, ld.ancil.csv, by.x=\"project_id\", by.y=\"AidData.Project.ID\"))\n\n}\n\nfilter.mfa <- function(dta)\n{\n  #Build a new vector with all 0s\n  #Change to 1 if there is evidence a LD focus is present\n  dta$LD.comp <- 0\n  names(dta)[\"X.y\" == names(dta)] <- \"LD_Bin.1\"\n  names(dta)[\"X\" == names(dta)] <- \"LD_Bin.2\"\n  \n  #If LD is identify as a sub-focus in either of the GEF analyses,\n  #Assign it a 1.\n  dta$LD.comp <- (dta$LD_Bin.1 == \"LD\" | dta$LD_Bin.2 == \"LD\")\n  dta$LD.comp[dta$LD.comp != TRUE] <- 0\n  dta$LD.comp[is.na(dta$LD.comp)] <- 0\n  dta$LD.comp[dta$LD.comp == TRUE] <- 1\n  \n  #Search for sub-foci AidData identified; to be completed with additional data.\n  #grep.str <- \"LD||Sustainable\"\n  #\"\\\\|SFM\\\\|REDD|LULUCF||Land||Degradation||Degredation||Sustainable\"\n  #grep(grep.str, as.character(dta$Sub.Foci), fixed=FALSE)\n  #table(dta$Sub.Foci)\n  \n  #No 'L's included; can be ignored.\n  #table(dta$List.of.project.s.focal.areas.x)\n\n  return(dta[dta$LD.comp == 1,])\n\n}\n\ntimeRangeAvg <- function(dta,prefix,affix,startyr,endyr)\n{\n  \n  searchS = paste(\"^\",prefix,startyr,affix,sep=\"\")\n  searchE = paste(\"^\",prefix,endyr,affix,sep=\"\")\n  \n  strt_id <- grep(searchS,colnames(dta))\n  end_id <- grep(searchE,colnames(dta))\n\n  \n  rmean <- rowMeans(dta[strt_id[[1]]:end_id[[length(end_id)]]], \n                    na.rm=TRUE)\n  return(rmean)\n}\n\ntimeRangeSum <- function(dta,prefix,affix,startyr,endyr)\n{\n  \n  searchS = paste(\"^\",prefix,startyr,affix,sep=\"\")\n  searchE = paste(\"^\",prefix,endyr,affix,sep=\"\")\n  \n  \n  strt_id <- grep(searchS,colnames(dta))\n  end_id <- grep(searchE,colnames(dta))\n  \n  rsum <- rowSums(dta[strt_id[[1]]:end_id[[length(end_id)]]], \n                  na.rm=TRUE)\n  return(rsum)\n}\n\n\ngeofilter.mfa <- function(dta)\n{\n  dta <- dta[dta$Location.Type != \"ADM1\",]\n  dta <- dta[dta$Location.Type != \"ADM1H\",]\n  dta <- dta[dta$Location.Type != \"PCLI\",]\n  return(dta)\n}\n\n\ntemp.sum <- function(dta)\n{\n  source(\"~/Desktop/Github/GEF_MFA/data_processing/MFA_data_functions.R\")\n  source(\"~/Desktop/Github/GEF_MFA/Analyses/causal_tree_functions.R\")\n  \n  #Drop locations with no start date\n  dtaA <- dta[!is.na(dta$Actual.date.of.implementation.start),]\n  dtaB <- dtaA[!(as.character(dtaA$Actual.date.of.implementation.start) == \"\"),]\n  \n  dtaB$start.date <- as.Date(dtaB$Actual.date.of.implementation.start, format=\"%d-%b-%y\")\n  \n  \n  dtaB$post_implementation_time <- (2014-  as.numeric( format( dtaB$start.date, '%Y')))\n  \n  dtaB$year <- as.numeric( format( dtaB$start.date, '%Y'))\n  \n  #Remove time periods for which we have insufficient data.\n  dtaB <- dtaB[!(dtaB$year >= 2014),]\n  dtaB <- dtaB[!(dtaB$year <= 2002),]\n  \n  #Calculate pre-trends\n  dtaB$LTDR_outcome_mean <- NA\n  dtaB$LTDR_outcome_max <- NA\n  dtaB$pre_average_precip <- NA\n  dtaB$pre_max_precip <- NA\n  dtaB$pre_min_precip <- NA\n  dtaB$pre_average_temp <- NA\n  dtaB$pre_max_temp <- NA\n  dtaB$pre_min_temp <- NA\n  \n  #Other pre-averages\n  dtaB$pre_average_NTL <- NA\n  dtaB$pre_average_LTDR <- NA\n  dtaB$pre_max_LTDR <- NA\n  \n  for(i in 1:length(dtaB[[1]]))\n  {\n    loc_year <- dtaB$year[[i]]\n    dtaB$pre_average_precip[[i]] <- timeRangeAvg(dtaB[i,], \"udel_precip_v4_01_yearly_mean.\", \".mean\", 1982, loc_year)\n    dtaB$pre_max_precip[[i]] <- timeRangeAvg(dtaB[i,], \"udel_precip_v4_01_yearly_max.\", \".mean\", 1982, loc_year)\n    dtaB$pre_min_precip[[i]] <- timeRangeAvg(dtaB[i,], \"udel_precip_v4_01_yearly_min.\", \".mean\", 1982, loc_year)\n    dtaB$pre_average_temp[[i]] <- timeRangeAvg(dtaB[i,], \"udel_air_temp_v4_01_yearly_mean.\", \".mean\", 1982, loc_year)\n    dtaB$pre_max_temp[[i]] <- timeRangeAvg(dtaB[i,], \"udel_air_temp_v4_01_yearly_max.\", \".mean\", 1982, loc_year)\n    dtaB$pre_min_temp[[i]] <- timeRangeAvg(dtaB[i,], \"udel_air_temp_v4_01_yearly_min.\", \".mean\", 1982, loc_year)\n    \n    \n    #Other pre-averages\n    dtaB$pre_average_NTL[[i]] <- timeRangeAvg(dtaB[i,], \"v4composites_calibrated.\", \".mean\", 1992, loc_year)\n    dtaB$pre_average_LTDR[[i]] <- timeRangeAvg(dtaB[i,], \"ltdr_yearly_ndvi_mean.\", \".mean\", 1982, loc_year)\n    dtaB$pre_max_LTDR[[i]] <- timeRangeAvg(dtaB[i,], \"ltdr_yearly_ndvi_max.\", \".mean\", 1982, loc_year)\n    \n    dtaB$LTDR_outcome_mean[[i]] <- timeRangeAvg(dtaB[i,], \"ltdr_yearly_ndvi_mean.\", \".mean\", loc_year, 2014) /10000\n    dtaB$LTDR_outcome_max[[i]] <- timeRangeAvg(dtaB[i,], \"ltdr_yearly_ndvi_max.\", \".mean\", loc_year, 2014) / 10000\n    \n    dtaB$Hansen_loss[[i]] <- timeRangeAvg(dtaB[i,], \"lossyr25.na.categorical_\", \"\", loc_year, 2013) / dtaB$lossyear.na.categorical_count[[i]]\n    \n  }\n  \n  return(dtaB)\n  \n}",
    "created" : 1480703989806.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1702225011",
    "id" : "46F0883A",
    "lastKnownWriteTime" : 1479311007,
    "last_content_update" : 1479311007,
    "path" : "~/Desktop/Github/GEF_MFA/data_processing/MFA_data_functions.R",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 5,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}